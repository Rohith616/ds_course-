{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_SparkSQL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0uQpQC8R27t"
      },
      "source": [
        "# Spark SQL\n",
        "\n",
        "SQL has been around since the 1970s, and so one can imagine the number of people who made it their bread and butter. As big data came into popularity, the number of professionals with the technical knowledge to deal with it was in shortage. This led to the creation of Spark SQL. To quote the docs:\n",
        "\n",
        "\n",
        ">Spark SQL is a Spark module for structured data processing. Unlike the basic Spark RDD API, the interfaces provided by Spark SQL provide Spark with more information about the structure of both the data and the computation being performed. Internally, Spark SQL uses this extra information to perform extra optimizations.\n",
        "\n",
        "Basically, what you need to know is that Spark SQL is used to execute SQL queries on big data. Spark SQL can also be used to read data from Hive tables and views. Let me explain Spark SQL with an example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUkjZZS7L9l5",
        "outputId": "201b5c24-ecdc-4acd-edf9-5df9c76c53b4"
      },
      "source": [
        "!wget https://gist.githubusercontent.com/ghaiyur-musubi/2b752601de1ae266a7fbe146629b0dce/raw/43791c2be6694fb443dddce7819be322b1e11967/cars.csv"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-10 18:10:47--  https://gist.githubusercontent.com/ghaiyur-musubi/2b752601de1ae266a7fbe146629b0dce/raw/43791c2be6694fb443dddce7819be322b1e11967/cars.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22201 (22K) [text/plain]\n",
            "Saving to: ‘cars.csv’\n",
            "\n",
            "cars.csv            100%[===================>]  21.68K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-08-10 18:10:48 (8.97 MB/s) - ‘cars.csv’ saved [22201/22201]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdQ7Un6RL-3e",
        "outputId": "9b19aa1a-06df-4199-82bc-94b4066f35f0"
      },
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kooZ7oH_MjA1",
        "outputId": "9679657c-f867-4513-9e4d-d9e829546f63"
      },
      "source": [
        "df = spark.read.csv('cars.csv', header=True, sep=\";\")\n",
        "df.show(5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|                 Car| MPG|Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|\n",
            "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|Chevrolet Chevell...|18.0|        8|       307.0|     130.0| 3504.|        12.0|   70|    US|\n",
            "|   Buick Skylark 320|15.0|        8|       350.0|     165.0| 3693.|        11.5|   70|    US|\n",
            "|  Plymouth Satellite|18.0|        8|       318.0|     150.0| 3436.|        11.0|   70|    US|\n",
            "|       AMC Rebel SST|16.0|        8|       304.0|     150.0| 3433.|        12.0|   70|    US|\n",
            "|         Ford Torino|17.0|        8|       302.0|     140.0| 3449.|        10.5|   70|    US|\n",
            "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6nDpMUINBP6",
        "outputId": "dca4e9f4-d803-4382-858f-63c958e88829"
      },
      "source": [
        "# Load data\n",
        "df = spark.read.csv('cars.csv', header=True, sep=\";\")\n",
        "# Register Temporary Table\n",
        "df.createOrReplaceTempView(\"temp\")\n",
        "# Select all data from temp table\n",
        "spark.sql(\"select * from temp limit 5\").show()\n",
        "# Select count of data in table\n",
        "spark.sql(\"select count(*) as Total_Count from temp\").show()\n",
        "# Select distinct cars in table \n",
        "spark.sql(\"select distinct Car from temp\").show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|                 Car| MPG|Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|\n",
            "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "|Chevrolet Chevell...|18.0|        8|       307.0|     130.0| 3504.|        12.0|   70|    US|\n",
            "|   Buick Skylark 320|15.0|        8|       350.0|     165.0| 3693.|        11.5|   70|    US|\n",
            "|  Plymouth Satellite|18.0|        8|       318.0|     150.0| 3436.|        11.0|   70|    US|\n",
            "|       AMC Rebel SST|16.0|        8|       304.0|     150.0| 3433.|        12.0|   70|    US|\n",
            "|         Ford Torino|17.0|        8|       302.0|     140.0| 3449.|        10.5|   70|    US|\n",
            "+--------------------+----+---------+------------+----------+------+------------+-----+------+\n",
            "\n",
            "+-----------+\n",
            "|Total_Count|\n",
            "+-----------+\n",
            "|        406|\n",
            "+-----------+\n",
            "\n",
            "+--------------------+\n",
            "|                 Car|\n",
            "+--------------------+\n",
            "|Volkswagen 1131 D...|\n",
            "|Chevrolete Chevel...|\n",
            "|Chevrolet Monte C...|\n",
            "|     Ford LTD Landau|\n",
            "|       Honda Prelude|\n",
            "|      Chevrolet Nova|\n",
            "|   Volkswagen Rabbit|\n",
            "|     Ford Torino 500|\n",
            "|        Toyota Camry|\n",
            "|         Audi 100 LS|\n",
            "|Plymouth Valiant ...|\n",
            "|Toyota Corolla Ma...|\n",
            "|Oldsmobile Cutlas...|\n",
            "|Fiat 124 Sport Coupe|\n",
            "|     Volvo 145e (sw)|\n",
            "|Chevrolet Caprice...|\n",
            "|            Audi Fox|\n",
            "|    Chevrolet Camaro|\n",
            "|       Dodge Aspen 6|\n",
            "|    Pontiac Catalina|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVYW1bUoTrlq"
      },
      "source": [
        "As you can see, we registered the dataframe as temporary table and then ran basic SQL queries on it. How amazing is that?!\n",
        "If you are a person who is more comfortable with SQL, then this feature is truly a blessing ,But this raises a question:\n",
        "\n",
        ">Should I just keep using Spark SQL all the time?\n",
        "\n",
        "And the answer is, it depends.\n",
        "So basically, the different functions acts in differnet ways, and depending upon the type of action you are trying to do, the speed at which it completes execution also differs. But as time progress, this feature is getting better and better, so hopefully the difference should be a small margin. There are plenty of analysis done on this, but nothing has a definite answer yet.\n",
        "\n"
      ]
    }
  ]
}