{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DR-eO17geWu"
   },
   "source": [
    "<img src=\"data:image/png;base64,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\" width=\"450\" height=\"550\">",
    "\n",
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Source: https://drive.google.com/drive/folders/15SG-chdqEwcrNAY39RTZJjvl-UwiZo_e?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "sCV30xyVhFbE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNsbAlSE3sBD"
   },
   "source": [
    "#### Specifying the TensorFlow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FIleuCAjoFD8",
    "outputId": "284971a2-8cde-4c4d-bfda-55e134d864ed"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BD0VFUpg3TLh"
   },
   "source": [
    "#### Testing for GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1-YOricU3Vcw",
    "outputId": "fe912f6f-17ae-4691-dd3e-9ba61931629b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2Xd1N_E4C5N"
   },
   "source": [
    "#### Mounting Google Drive locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1xHAdlBCzWuc",
    "outputId": "cb35091b-3a85-48b5-becd-cd7d09bbdc4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/data; to attempt to forcibly remount, call drive.mount(\"/content/data\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "zN_8A2-OzYLj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/data/My Drive/KRISHNA/CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvE-heJNo3GG"
   },
   "source": [
    "#### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0koUcJMJpEBD",
    "outputId": "ada77775-851a-4ea4-8313-4601c29ee958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrCMmGw9pHys"
   },
   "source": [
    "#### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SH4WzfOhpKc3",
    "outputId": "b1360312-0dc4-4fc8-81c6-fe92158eab01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af8O4l90gk7B"
   },
   "source": [
    "## Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "#### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "SAUt4UMPlhLS"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "#### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "XPzPrMckl-hV"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tf87FpvxmNOJ"
   },
   "source": [
    "#### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ncpqPl69mOac"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaTOgD8rm4mU"
   },
   "source": [
    "#### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "i_-FZjn_m8gk"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "#### Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "6AZeOGCvnNZn"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAoSECOm203v"
   },
   "source": [
    "#### Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "8GtmUlLd26Nq"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTldFvbX28Na"
   },
   "source": [
    "#### Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "1p_Zj1Mc3Ko_"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOlZ8rlc2rjG"
   },
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hrbq_uHf2kx-",
    "outputId": "cdbd19c8-c740-4782-d7a4-bdf825319bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 813,217\n",
      "Trainable params: 813,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6XkI90snSDl"
   },
   "source": [
    "## Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "#### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "NALksrNQpUlJ"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUj1W4PJptta",
    "outputId": "aaadb78b-f217-400a-ffdf-43c76279cdec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "125/125 [==============================] - 1219s 10s/step - loss: 0.6897 - accuracy: 0.5332 - val_loss: 0.6800 - val_accuracy: 0.5610\n",
      "Epoch 2/25\n",
      "125/125 [==============================] - 40s 318ms/step - loss: 0.6666 - accuracy: 0.5960 - val_loss: 0.6215 - val_accuracy: 0.6690\n",
      "Epoch 3/25\n",
      "125/125 [==============================] - 38s 307ms/step - loss: 0.6349 - accuracy: 0.6417 - val_loss: 0.6097 - val_accuracy: 0.7070\n",
      "Epoch 4/25\n",
      "125/125 [==============================] - 39s 309ms/step - loss: 0.6029 - accuracy: 0.6740 - val_loss: 0.5695 - val_accuracy: 0.7180\n",
      "Epoch 5/25\n",
      "125/125 [==============================] - 41s 328ms/step - loss: 0.5546 - accuracy: 0.7193 - val_loss: 0.5584 - val_accuracy: 0.7140\n",
      "Epoch 6/25\n",
      "125/125 [==============================] - 39s 312ms/step - loss: 0.5338 - accuracy: 0.7330 - val_loss: 0.5454 - val_accuracy: 0.7220\n",
      "Epoch 7/25\n",
      "125/125 [==============================] - 44s 349ms/step - loss: 0.5024 - accuracy: 0.7500 - val_loss: 0.5425 - val_accuracy: 0.7310\n",
      "Epoch 8/25\n",
      "125/125 [==============================] - 39s 311ms/step - loss: 0.4844 - accuracy: 0.7765 - val_loss: 0.5011 - val_accuracy: 0.7620\n",
      "Epoch 9/25\n",
      "125/125 [==============================] - 38s 306ms/step - loss: 0.4589 - accuracy: 0.7853 - val_loss: 0.6180 - val_accuracy: 0.6930\n",
      "Epoch 10/25\n",
      "125/125 [==============================] - 39s 315ms/step - loss: 0.4421 - accuracy: 0.7853 - val_loss: 0.5226 - val_accuracy: 0.7560\n",
      "Epoch 11/25\n",
      "125/125 [==============================] - 39s 308ms/step - loss: 0.4341 - accuracy: 0.8015 - val_loss: 0.4827 - val_accuracy: 0.7890\n",
      "Epoch 12/25\n",
      "125/125 [==============================] - 38s 304ms/step - loss: 0.4061 - accuracy: 0.8150 - val_loss: 0.4925 - val_accuracy: 0.7900\n",
      "Epoch 13/25\n",
      "125/125 [==============================] - 38s 307ms/step - loss: 0.4028 - accuracy: 0.8125 - val_loss: 0.4880 - val_accuracy: 0.7780\n",
      "Epoch 14/25\n",
      "125/125 [==============================] - 39s 312ms/step - loss: 0.3907 - accuracy: 0.8202 - val_loss: 0.4677 - val_accuracy: 0.8030\n",
      "Epoch 15/25\n",
      "125/125 [==============================] - 39s 313ms/step - loss: 0.3742 - accuracy: 0.8288 - val_loss: 0.4712 - val_accuracy: 0.7830\n",
      "Epoch 16/25\n",
      "125/125 [==============================] - 38s 307ms/step - loss: 0.3541 - accuracy: 0.8382 - val_loss: 0.4884 - val_accuracy: 0.7680\n",
      "Epoch 17/25\n",
      "125/125 [==============================] - 38s 304ms/step - loss: 0.3316 - accuracy: 0.8508 - val_loss: 0.5080 - val_accuracy: 0.7750\n",
      "Epoch 18/25\n",
      "125/125 [==============================] - 39s 314ms/step - loss: 0.3351 - accuracy: 0.8518 - val_loss: 0.4935 - val_accuracy: 0.7830\n",
      "Epoch 19/25\n",
      "125/125 [==============================] - 39s 313ms/step - loss: 0.3155 - accuracy: 0.8627 - val_loss: 0.4979 - val_accuracy: 0.7780\n",
      "Epoch 20/25\n",
      "125/125 [==============================] - 38s 307ms/step - loss: 0.2930 - accuracy: 0.8758 - val_loss: 0.5443 - val_accuracy: 0.7710\n",
      "Epoch 21/25\n",
      "125/125 [==============================] - 39s 311ms/step - loss: 0.2781 - accuracy: 0.8835 - val_loss: 0.5341 - val_accuracy: 0.7700\n",
      "Epoch 22/25\n",
      "125/125 [==============================] - 40s 317ms/step - loss: 0.2614 - accuracy: 0.8903 - val_loss: 0.5266 - val_accuracy: 0.7880\n",
      "Epoch 23/25\n",
      "125/125 [==============================] - 39s 312ms/step - loss: 0.2345 - accuracy: 0.9032 - val_loss: 0.5290 - val_accuracy: 0.8010\n",
      "Epoch 24/25\n",
      "125/125 [==============================] - 39s 313ms/step - loss: 0.2420 - accuracy: 0.8953 - val_loss: 0.6057 - val_accuracy: 0.7700\n",
      "Epoch 25/25\n",
      "125/125 [==============================] - 38s 307ms/step - loss: 0.2297 - accuracy: 0.9047 - val_loss: 0.5710 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f59c94d7630>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "gsSiWEJY1BPB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ED9KB3I54c1i",
    "outputId": "8f692c87-d4ec-4cc9-c8ec-38b819bd6805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_Implementation(Image Classification).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
