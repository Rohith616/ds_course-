{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Tutorial\n",
    "\n",
    "<br><br>\n",
    "<img src=\"https://i.imgur.com/2GXmcvN.png\" width=\"700\" hight = \"600\" > <br><br>\n",
    "\n",
    "\n",
    "**Convolutional Neural Network** is one of the main categories to do image classification and image recognition in neural networks. Scene labeling, objects detections, and face recognition, etc., are some of the areas where convolutional neural networks are widely used.\n",
    "\n",
    "CNN takes an image as input, which is classified and process under a certain category such as dog, cat, lion, tiger, etc. The computer sees an image as an array of pixels and depends on the resolution of the image. Based on image resolution, it will see as <b>h * w * d</b>, where h= height w= width and d= dimension. For example, An RGB image is <b>6 * 6 * 3</b> array of the matrix, and the grayscale image is <b>4 * 4 * 1</b> array of the matrix.\n",
    "\n",
    "In CNN, each input image will pass through a sequence of convolution layers along with pooling, fully connected layers, filters (Also known as kernels). After that, we will apply the Soft-max function to classify an object with probabilistic values 0 and 1.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/FLtPNbD.png\" width=\"700\" hight = \"500\" > <br>\n",
    "\n",
    "\n",
    "## Convolution Layer\n",
    "\n",
    "Convolution layer is the first layer to extract features from an input image. By learning image features using a small square of input data, the convolutional layer preserves the relationship between pixels. It is a mathematical operation which takes two inputs such as image matrix and a kernel or filter.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/cH8PwEE.png\" width=\"1200\" hight = \"800\" > <br>\n",
    "\n",
    "## Strides\n",
    "\n",
    "Stride is the number of pixels which are shift over the input matrix. When the stride is equal to 1, then we move the filters to 1 pixel at a time and similarly, if the stride is equal to 2, then we move the filters to 2 pixels at a time. The following figure shows that the convolution would work with a stride of 2.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/21Pg9Dl.png\" width=\"700\" hight = \"600\" > <br>\n",
    "\n",
    "## Padding\n",
    "\n",
    "Padding plays a crucial role in building the convolutional neural network. If the image will get shrink and if we will take a neural network with 100's of layers on it, it will give us a small image after filtered in the end.\n",
    "\n",
    "If we take a three by three filter on top of a grayscale image and do the convolving then what will happen?\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/pkGIrTl.png\" width=\"800\" hight = \"700\" > <br>\n",
    "\n",
    "It is clear from the above picture that the pixel in the corner will only get covers one time, but the middle pixel will get covered more than once. It means that we have more information on that middle pixel, so there are two downsides:\n",
    "\n",
    "- Shrinking outputs\n",
    "- Losing information on the corner of the image.\n",
    "\n",
    "To overcome this, we have introduced padding to an image. \n",
    "\n",
    "**\"Padding is simply a process of adding layers to our input images so as to avoid the problems mentioned above.\"**\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/s8Ub8TZ.png\" width=\"450\" hight = \"400\" > <br>\n",
    "\n",
    "- This prevents shrinking as, \n",
    "    if **p =** number of layers of zeros added to the border of the image, then our **(n x n)** image becomes **(n + 2p) x (n + 2p)** after padding. So applying convolution-operation **(with (f x f) filter)**, outputs will be **(n + 2p – f + 1) x (n + 2p – f + 1)**. \n",
    "    **For example,** adding one layer of **padding** to an **(8 x 8)** image and using a **(3 x 3)** filter we would get an **(8 x 8)** output after performing convolution operation.\n",
    "\n",
    "\n",
    "- This increases the contribution of the pixels at the border of the original image by bringing them into the middle of the padded image. Thus, information on the borders is preserved as well as the information in the middle of the image.\n",
    "\n",
    "<br>\n",
    "\n",
    "## ReLU Layer\n",
    "\n",
    "ReLU stands for the **rectified linear unit**. Once the feature maps are extracted, the next step is to move them to a ReLU layer. \n",
    "\n",
    "ReLU performs an element-wise operation and sets all the negative pixels to 0. It introduces non-linearity to the network, and the generated output is a rectified feature map. Below is the graph of a ReLU function:\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/oRxY9rf.png\" width=\"600\" hight = \"500\" > <br>\n",
    "\n",
    "\n",
    "## Pooling Layer\n",
    "\n",
    "Pooling layer plays an important role in pre-processing of an image. Pooling layer reduces the number of parameters when the images are too large. Pooling is **\"downscaling\"** of the image obtained from the previous layers. It can be compared to shrinking an image to reduce its pixel density. Spatial pooling is also called downsampling or subsampling, which reduces the dimensionality of each map but retains the important information. There are the following types of spatial pooling:\n",
    "\n",
    "## Max Pooling\n",
    "\n",
    "Max pooling is a **sample-based discretization process.** Its main objective is to downscale an input representation, reducing its dimensionality and allowing for the assumption to be made about features contained in the sub-region binned.\n",
    "\n",
    "Max pooling is done by applying a max filter to non-overlapping sub-regions of the initial representation.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/rYu8XFm.png\" width=\"800\" hight = \"800\" > \n",
    "\n",
    "## Average Pooling\n",
    "\n",
    "Down-scaling will perform through average pooling by dividing the input into rectangular pooling regions and computing the average values of each region.\n",
    "\n",
    "**Syntax**\n",
    "\n",
    "layer = averagePooling2dLayer(poolSize)\n",
    "layer = averagePooling2dLayer(poolSize,Name,Value)\n",
    "\n",
    "\n",
    "## Sum Pooling\n",
    "\n",
    "The sub-region for **sum pooling** or **mean pooling** are set exactly the same as for **max-pooling** but instead of using the max function we use sum or mean.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Fully Connected Layer\n",
    "\n",
    "The fully connected layer is a layer in which the input from the other layers will be flattened into a vector and sent. It will transform the output into the desired number of classes by the network.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/OoPI95y.png\" width=\"800\" hight = \"600\" > <br>\n",
    "\n",
    "In the above diagram, the feature map matrix will be converted into the vector such as **x1, x2, x3... xn** with the help of fully connected layers. We will combine features to create a model and apply the activation function such as **softmax** or **sigmoid** to classify the outputs as a car, dog, truck, etc.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/iTmqRJK.png\" width=\"800\" hight = \"600\" > <br>\n",
    "\n",
    "\n",
    "#### Here’s how the structure of the convolution neural network looks so far:\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/jUWQ3cg.png\" width=\"800\" hight = \"600\" > <br>\n",
    "\n",
    "The next step in the process is called flattening. Flattening is used to convert all the resultant 2-Dimensional arrays from pooled feature maps into a single long continuous linear vector.\n",
    "\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/UVKMDlt.png\" width=\"700\" hight = \"600\" > <br>\n",
    "\n",
    "\n",
    "The flattened matrix is fed as input to the fully connected layer to classify the image.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/7rQNVED.png\" width=\"970\" hight = \"800\" > <br>\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/kfNEtRM.png\" width=\"970\" hight = \"800\" > <br>\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/cjjlns7.png\" width=\"970\" hight = \"800\" > <br>\n",
    "\n",
    "\n",
    "**Here’s how exactly CNN recognizes a bird:**\n",
    "\n",
    "- The pixels from the image are fed to the convolutional layer that performs the convolution operation \n",
    "- It results in a convolved map \n",
    "- The convolved map is applied to a ReLU function to generate a rectified feature map \n",
    "- The image is processed with multiple convolutions and ReLU layers for locating the features \n",
    "- Different pooling layers with various filters are used to identify specific parts of the image \n",
    "- The pooled feature map is flattened and fed to a fully connected layer to get the final output\n",
    "\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/HPIgTYf.png\" width=\"970\" hight = \"800\" > <br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
