{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Step_1_4d_Pandas__Data_Types__Missing_Data__Renaming_and_Combining.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h07qDZs-8he",
        "colab_type": "text"
      },
      "source": [
        "# Load Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCo58KFtWWTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yYOu6iGdXY6",
        "colab_type": "text"
      },
      "source": [
        "# Load Data Set\n",
        "\n",
        "- we'll load the housing price data to continue experimenting with Pandas\n",
        "\n",
        "- [here](https://www.kaggle.com/c/home-data-for-ml-course/data) is the source of the data \n",
        "  - find the \"Download All\" button to download the entire data set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl6U0WJ8rT-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the csv from drive (google drive in this case)\n",
        "data = pd.read_csv('/content/drive/My Drive/Datasets/home-data-for-ml-course/train.csv')\n",
        "# add your own path above to read the train.csv file\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtbBC6YrEem1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display the previously loaded DataFrame\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj95-i8bdhyH",
        "colab_type": "text"
      },
      "source": [
        "- in this notebook, you'll learn how to investigate data types within a DataFrame or Series. \n",
        "\n",
        "- you'll also learn how to find and replace entries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTCglgYEdqgK",
        "colab_type": "text"
      },
      "source": [
        "# Dtypes\n",
        "\n",
        "- the data type for a column in a DataFrame or a Series is known as the dtype\n",
        "\n",
        "- you can use the dtype property to grab the type of a specific column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t7NZXA2dxVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grab the data type of the SalePrice column\n",
        "data.SalePrice.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFWSyYF-fjnT",
        "colab_type": "text"
      },
      "source": [
        "- a DataFrame or Series index has its own `dtype` too:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzsDLnRpfmck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check data type of index column\n",
        "data.index.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omkyGP1Bd_V2",
        "colab_type": "text"
      },
      "source": [
        "- the `dtypes` property returns the dtype of every column in the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgyPFA1md45E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the data type of every column in the data DataFrame\n",
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MA6C82seijA",
        "colab_type": "text"
      },
      "source": [
        "- Data types tell us something about how pandas is storing the data internally\n",
        "  - `float64` means that it's using a 64-bit floating point number \n",
        "  - `int64` means a similarly sized integer instead, and so on.\n",
        "\n",
        "- one peculiarity to keep in mind is that columns consisting entirely of strings do not get their own type\n",
        "  - they are instead given the `object` type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq3TCWOKedZX",
        "colab_type": "text"
      },
      "source": [
        "### Type Conversion\n",
        "\n",
        "- It's possible to convert a column of one type into another wherever such a conversion makes sense by using the astype() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VTCfSTneFXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the SalePrice column to float64 from int64\n",
        "data.SalePrice.astype('float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbHBE4GMfxdi",
        "colab_type": "text"
      },
      "source": [
        "# Missing Values\n",
        "\n",
        "- entries missing values are given the value NaN, \n",
        "  - short for \"Not a Number\"\n",
        "  - these NaN values are always of the `float64` dtype\n",
        "\n",
        "- Pandas provides some methods specific to missing data \n",
        "  - to select `NaN` entries you can use `pd.isnull()` \n",
        "  - or its companion `pd.notnull()`to select non-null values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDZfiwNagHp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select all the entries which have null values for Fence\n",
        "data[pd.isnull(data.Fence)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6kk9QVhgcLb",
        "colab_type": "text"
      },
      "source": [
        "### replacing missing values \n",
        "\n",
        "- replacing missing values is a common operation\n",
        "- Pandas provides a really handy method for this problem: `fillna()` \n",
        "  - `fillna()` provides a few different strategies for mitigating missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YjFhgV3gqN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filling missing fence values with 'no fence' \n",
        "data.Fence.fillna('No Fence')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVxdS3hLg_Iy",
        "colab_type": "text"
      },
      "source": [
        "### replacing non-null data \n",
        "\n",
        "- we may have a non-null value that we would like to replace\n",
        "\n",
        "- it's handy for replacing missing data which is given some kind of sentinel value in the dataset: things like \"Unknown\", \"Undisclosed\", \"Invalid\", and so on.\n",
        "\n",
        "- for example here: lets say we want to replace the NoRidge neighborhood with NorthRidge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsJVgwkChYH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.Neighborhood.replace(\"NoRidge\",\"NorthRidge\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBfhvZ3DhvCt",
        "colab_type": "text"
      },
      "source": [
        "# Renaming \n",
        "\n",
        "- oftentimes, data will come to us with column names, index names, or other naming conventions that we are not satisfied with\n",
        "\n",
        "- in that case, there are pandas functions to change the names of the offending entries to something better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjCqy9LACUh3",
        "colab_type": "text"
      },
      "source": [
        "### Column Rename"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBxdf7ynhXsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change the Neighborhood column name to Locality\n",
        "data.rename(columns={'Neighborhood':'Locality'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2GTzrfDCJEw",
        "colab_type": "text"
      },
      "source": [
        "### Row Rename\n",
        "\n",
        "- `rename()` lets you rename index or column values by specifying a index or column keyword parameter respectively\n",
        "\n",
        "- it supports a variety of input formats, but usually a Python dictionary is the most convenient \n",
        "\n",
        "- here is an example using it to rename some elements of the index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHl1o8GtCa2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.rename(index={0:\"firstEntry\",1:\"secondEntry\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJCLLoX1C3zA",
        "colab_type": "text"
      },
      "source": [
        "##### `.set_index()`\n",
        "\n",
        "- you'll most likely rename columns very often, but rename index values very rarely\n",
        "  - for renaming index values, `set_index()` is usually more convenient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTj-EbWXDBcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the Id column as row labels\n",
        "data.set_index('Id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDfrc0SaDINA",
        "colab_type": "text"
      },
      "source": [
        "### `.rename_axis()`\n",
        "\n",
        "- both the row index and the column index can have their own name attribute \n",
        " \n",
        "- the complimentary `rename_axis()` method may be used to change these names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z0LZKx5Dgvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the label for rows as Houses and columns as Details\n",
        "data.rename_axis(\"Houses\",axis=\"rows\").rename_axis(\"Details\", axis=\"columns\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr7UXmO_EBDR",
        "colab_type": "text"
      },
      "source": [
        "# Combining \n",
        "\n",
        "- when performing operations on a dataset, we will sometimes need to combine different DataFrames and/or Series in non-trivial ways \n",
        "\n",
        "- pandas has three core methods for doing this; in order of increasing complexity, they are\n",
        "  - `concat()`, \n",
        "  - `join()`, and \n",
        "  - `merge()`\n",
        "  \n",
        "- most of what `merge()` can do can also be done more simply with `join()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXMgtKYbEct_",
        "colab_type": "text"
      },
      "source": [
        "### `concat()`\n",
        "\n",
        "- the simplest combining method is `concat()` \n",
        "\n",
        "- given a list of elements, this function will smush those elements together along an axis\n",
        "\n",
        "- this is useful when we have data in different DataFrame or Series objects but having the same fields (columns)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR7RzGR7PtdW",
        "colab_type": "text"
      },
      "source": [
        "##### Combining Series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0wG_3stPwrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s1 = pd.Series(['a', 'b']) # define series 1 \n",
        "s2 = pd.Series(['c', 'd']) # define series 2\n",
        "pd.concat([s1, s2]) # combine series 1 and 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcseYi3YP382",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clear the existing index and reset it in the result\n",
        "pd.concat([s1, s2], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPiUYm8yReKq",
        "colab_type": "text"
      },
      "source": [
        "##### Combining DataFrames\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H412rgVgRuPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define DataFrame 1 \n",
        "df1 = pd.DataFrame([['a', 1], ['b', 2]], columns=['letter', 'number'])\n",
        "\n",
        "# define DataFrame 2\n",
        "df2 = pd.DataFrame([['c', 3], ['d', 4]], columns=['letter', 'number'])\n",
        "\n",
        "# combine the two along column names, also reset indexes  \n",
        "pd.concat([df1, df2], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXQs_7U3SwS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define 3rd DataFrame \n",
        "df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']], columns=['letter', 'number', 'animal'])\n",
        "\n",
        "# combine everything along overlapping columns  \n",
        "pd.concat([df1,df3],sort=False,ignore_index=True)\n",
        "# unknown values are filled with NaNs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhfiVSYzTQb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine DataFrames with overlapping columns and return only those that are shared\n",
        "pd.concat([df1, df3], join=\"inner\",ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGWOIVxOWfIc",
        "colab_type": "text"
      },
      "source": [
        "### `.join()`\n",
        "\n",
        "- join columns of another DataFrame.\n",
        "\n",
        "- join columns with other DataFrame either on index or on a key column\n",
        "\n",
        "- efficiently join multiple DataFrame objects by index at once by passing a list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZsAIXW5WwcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# init one DataFrame\n",
        "df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
        "                   'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48X5dzNxXA9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# init another DataFrame\n",
        "\n",
        "other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
        "                      'B': ['B0', 'B1', 'B2']})\n",
        "\n",
        "other"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhZWIJ4GXGQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# join `df` with `other` using appropriate suffixes on `key` column of each DataFrame\n",
        "df.join(other, lsuffix='_caller', rsuffix='_other')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvW2ZibdXWn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to join along the key column, i.e. key as the index of the joined DataFrame:\n",
        "df.set_index('key').join(other.set_index('key'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ioj3e-s0X0Or",
        "colab_type": "text"
      },
      "source": [
        "### `.merge()`\n",
        "\n",
        "- merge DataFrame or named Series objects with a database-style join.\n",
        "\n",
        "- the join is done on columns or indexes \n",
        "  - if joining columns on columns, the DataFrame indexes will be ignored\n",
        "  - otherwise if joining indexes on indexes or indexes on a column or columns, the index will be passed on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgDWpKXSYLIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define one DataFrame \n",
        "df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
        "                    'value': [1, 2, 3, 5]})\n",
        "\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjXb6XdSYR9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define one DataFrame \n",
        "df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
        "                    'value': [5, 6, 7, 8]})\n",
        "\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d-1lL7rYcVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# merge df1 and df2 on the lkey and rkey columns \n",
        "# value columns have the default suffixes, _x and _y, appended\n",
        "df1.merge(df2, left_on='lkey', right_on='rkey')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pVcMGkyfSuX",
        "colab_type": "text"
      },
      "source": [
        "# Saving Data Files\n",
        "\n",
        "- Series and DataFrames can be written to files\n",
        "  - most popular file format written to `.csv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vio1QzBlf6zJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create and write DataFrame to CSV file\n",
        "\n",
        "df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
        "                   'mask': ['red', 'purple'],\n",
        "                   'weapon': ['sai', 'bo staff']})\n",
        "# check dataframe \n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcyh2r-4gvb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ouptut data frame to save file names `output.csv`\n",
        "df.to_csv('output.csv',index=False) \n",
        "# check working directory for "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}